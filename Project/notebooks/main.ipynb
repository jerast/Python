{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PredicciÃ³n Ventas de Yamaha 2024-2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First Steps**\n",
    "\n",
    "Set init imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas\n",
    "import numpy\n",
    "import seaborn\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Project params\n",
    "data_filter = 'modelo' # [asesor, modelo]\n",
    "data_values = 'cantidad' # [cantidad, costo]\n",
    "\n",
    "data_time_start = '2019' # =>  2022-01-01\n",
    "data_time_end = '2024' # =>  2024-01-01\n",
    "\n",
    "show_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables according Project params\n",
    "filter_mappings = {\n",
    "   'asesor': 'nom_asesor',\n",
    "   'modelo': 'modelo',\n",
    "   'clasificacion': 'clasificacion'\n",
    "}\n",
    "values_mappings = {\n",
    "   'cantidad': {\n",
    "      'name': 'cantidad',\n",
    "      'type': int\n",
    "   },\n",
    "   'costo': {\n",
    "      'name': 'costo_unitario',\n",
    "      'type': float\n",
    "   }\n",
    "}\n",
    "\n",
    "selected_filter = filter_mappings.get(data_filter)\n",
    "selected_value = values_mappings.get(data_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get and Prepare Data**\n",
    "\n",
    "Data connection, cleaning, normalize, filter and sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data files paths\n",
    "import os\n",
    "\n",
    "query_path = '../assets/query.sql'\n",
    "normalize_path = f'../assets/{data_filter}.csv'\n",
    "\n",
    "data_path = '../assets/data.csv'\n",
    "data_clean_path = '../assets/data_cleaned.csv'\n",
    "data_normalized_path = '../assets/data_normalized.csv'\n",
    "data_filter_path = '../assets/data_filtered.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get connection env variables \n",
    "if not os.path.exists(data_path):\n",
    "\n",
    "   import dotenv\n",
    "\n",
    "   dotenv.load_dotenv( )\n",
    "\n",
    "   DRIVER = 'ODBC Driver 18 for SQL Server'\n",
    "   SERVER = os.getenv('PROJECT_SERVER')\n",
    "   DATABASE = os.getenv('PROJECT_DATABASE')\n",
    "   USERNAME = os.getenv('PROJECT_USERNAME')\n",
    "   PASSWORD = os.getenv('PROJECT_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from DB\n",
    "if not os.path.exists(data_path):\n",
    "\n",
    "   # import pyodbc\n",
    "   import sqlalchemy\n",
    "   \n",
    "   # Get SQL query from file\n",
    "   with open(query_path) as file:\n",
    "      sql_query = file.read()\n",
    "\n",
    "   # PyODBC connection\n",
    "   # pyodbc_connection_string = f'DRIVER={DRIVER};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD};TrustServerCertificate=YES;'\n",
    "   # pyodbc_connection = pyodbc.connect(pyodbc_connection_string)\n",
    "\n",
    "   # SQLAlquemy connection\n",
    "   sqlalchemy_connection_string = f'mssql+pyodbc://{USERNAME}:{PASSWORD}@{SERVER}/{DATABASE}?driver={DRIVER}&TrustServerCertificate=yes'\n",
    "   sqlalchemy_engine = sqlalchemy.create_engine(sqlalchemy_connection_string)\n",
    "\n",
    "   # Excecute query with pandas\n",
    "   query = pandas.read_sql_query(sql_query, sqlalchemy_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "if not os.path.exists(data_path):   \n",
    "   \n",
    "   fetched_data = pandas.DataFrame(query)\n",
    "   fetched_data.to_csv(data_path, index=False, header=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to clean\n",
    "with open(data_path, 'r') as file:\n",
    "   data = file.read().split('\\n')\n",
    "\n",
    "   headers = data.pop(0)\n",
    "   clean_data = '\\n'.join(data)\n",
    "\n",
    "   print(data[0] +'\\n'+ data[17792] +'\\n'+ data[8667] +'\\n'+ data[30405])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data by removing extra characters\n",
    "\n",
    "# decimals to int values\n",
    "clean_data = clean_data.replace('.0;', ';')\n",
    "# extra commas\n",
    "clean_data = clean_data.replace(',', '')\n",
    "# double spaces at start and end of any cell\n",
    "clean_data = clean_data.replace('; ', ';')\n",
    "clean_data = clean_data.replace(' ;', ';')\n",
    "# double spaces at middle of any cell\n",
    "clean_data = clean_data.replace('\\n', '_')\n",
    "clean_data = ' '.join(clean_data.split())\n",
    "clean_data = clean_data.replace('_', '\\n')\n",
    "# extra quotation marks\n",
    "clean_data = clean_data.replace('\"', '')\n",
    "\n",
    "\n",
    "clean_data = clean_data.split('\\n')\n",
    "print(clean_data[0] +'\\n'+ clean_data[17792] +'\\n'+ clean_data[8667] +'\\n'+ clean_data[30405])\n",
    "clean_data = '\\n'.join(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "headers = headers.replace(';', ',')\n",
    "clean_data = clean_data.replace(';', ',')\n",
    "\n",
    "with open(data_clean_path, 'w') as file:\n",
    "   file.write(headers + '\\n' + clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to normalize\n",
    "if os.path.exists(normalize_path):\n",
    "   normalize_data = pandas.read_csv(data_clean_path)\n",
    "   \n",
    "normalize_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalization params\n",
    "if os.path.exists(normalize_path):\n",
    "\n",
    "   with open(normalize_path, mode='r', encoding='utf-8') as file:\n",
    "      norms = file.read().replace('\\n', ',').split(',')\n",
    "      norms = norms[2:]\n",
    "      norms = numpy.reshape(norms, (-1, 2))\n",
    "\n",
    "   # Convert normalization csv to dict\n",
    "   normalization = {}\n",
    "   for model, norm_value in norms:\n",
    "      normalization[model] = norm_value\n",
    "\n",
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert normalized data in a new Column\n",
    "if os.path.exists(normalize_path):\n",
    "\n",
    "   normalize_data['modelo'] = normalize_data['des_modelo'].apply(lambda x: normalization.get(x))\n",
    "normalize_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save normalized data\n",
    "if os.path.exists(normalize_path):\n",
    "   \n",
    "   normalize_data.to_csv(data_normalized_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to filter\n",
    "filter_data = pandas.read_csv(data_normalized_path, parse_dates=['fecha'], date_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecesary columns\n",
    "filter_data = filter_data.drop(columns=['sw', 'bodega', 'ident_asesor', 'ident_cliente', 'nom_cliente', 'utilidad', 'financiera', 'dias_inv', 'doc_ref'])\n",
    "filter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by time-range Project params\n",
    "filter_data = filter_data[(data_time_start <= filter_data['fecha']) & (filter_data['fecha']<= data_time_end)]\n",
    "filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group dataframe by ['fecha'] as primary and [selected_filter] as secondary\n",
    "filter_data_group = filter_data.groupby([pandas.Grouper(key='fecha', freq='D', sort=True), selected_filter])[selected_value['name']].sum()\n",
    "filter_data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert group series in a new dataframe\n",
    "data_filtered = filter_data_group.unstack(level=1)\n",
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN and format int columns\n",
    "data_filtered = data_filtered.fillna(0)\n",
    "data_filtered = data_filtered.astype(selected_value['type'])\n",
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'TOTAL' by Time\n",
    "data_filtered['TOTAL'] = data_filtered.sum(axis='columns')\n",
    "# data_filtered.loc['Total']= data_filtered.sum()\n",
    "\n",
    "data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered_data\n",
    "data_filtered.to_csv(data_filter_path, date_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group dataframe by ['modelo'] as primary and ['des_modelo'] as secondary\n",
    "sort_data_group = filter_data.groupby(['modelo', 'des_modelo'])[selected_value['name']].sum()\n",
    "sort_data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Items by Value\n",
    "sort_data = filter_data.groupby(selected_filter)[selected_value['name']].sum()\n",
    "sort_data = sort_data.reset_index()\n",
    "sort_data = sort_data.sort_values(by='cantidad', ascending=False)\n",
    "sort_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Display Data**\n",
    "\n",
    "Display sample graphs of the prepared data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pandas.read_csv('../assets/data_filtered.csv', parse_dates=['fecha'], date_format='%Y-%m-%d', dtype=selected_value['type'])\n",
    "\n",
    "# Extract Items and Time\n",
    "items = list(data.iloc[:, 1:-1].keys())\n",
    "time = numpy.asarray(data['fecha'], dtype='datetime64[s]')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Items all-in-one plot\n",
    "if show_plots:\n",
    "   \n",
    "   figure, ax = pyplot.subplots(figsize=(12, 4))\n",
    "\n",
    "   ax.plot(time, data[items], lw=1)\n",
    "   ax.tick_params(axis='x', labelrotation=0)\n",
    "   ax.set_title(f'No. de Ventas {data_time_start} - {data_time_end}')\n",
    "   ax.set_xlabel('Fecha')\n",
    "   ax.set_ylabel('Ventas')\n",
    "   ax.margins(x=0.03, y=0.02)\n",
    "   ax.grid()\n",
    "\n",
    "   figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-10 Items - filtered data\n",
    "items_top_10 = list( sort_data['modelo'].head(10) )\n",
    "\n",
    "# Config plots for this Items subgroup\n",
    "cols = 2\n",
    "rows = 5\n",
    "size = (10, 8)\n",
    "y_limit = (0, data[items].max().max())\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-10 items same-scaled separated plots\n",
    "if show_plots:\n",
    "    figure_a, axes_a = pyplot.subplots(nrows=rows, ncols=cols, figsize=size)\n",
    "\n",
    "    for index, item in enumerate(items_top_10):\n",
    "        ax = axes_a[int(index/cols), int(index%cols)]\n",
    "        ax.plot(time, data[item], label=item, color=colors[int(index%10)], lw=1)\n",
    "        ax.tick_params(axis='x', labelrotation=0)\n",
    "        ax.set(ylim=y_limit)\n",
    "        ax.legend()\n",
    "        # ax.grid()\n",
    "\n",
    "    figure_a.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-10 First & Last items - filtered data \n",
    "items_first_last = [ items_top_10[0], items_top_10[-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-10 First & Last items VS total sales relation - filtered data \n",
    "if show_plots:\n",
    "   figure_b, axes_b = pyplot.subplots(nrows=2, ncols=1, figsize=(14, 7))\n",
    "\n",
    "   for index, key in enumerate(items_first_last):\n",
    "      ax = axes_b[index]\n",
    "      ax.plot(time, data['TOTAL'], label='Total', lw=1)\n",
    "      ax.plot(time, data[key], label=key, lw=1)\n",
    "      ax.tick_params(axis='x', labelrotation=0)\n",
    "      ax.margins(x=0.03, y=0.04)\n",
    "      # ax.grid()\n",
    "      ax.set(\n",
    "         title=f'{key}',\n",
    "         # xlabel='Fecha', \n",
    "         # ylabel='No. de Ventas',\n",
    "      )\n",
    "      ax.legend()\n",
    "\n",
    "   figure_b.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
